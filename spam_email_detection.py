# -*- coding: utf-8 -*-
"""Spam Email Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YETqJvKx-_0Mj4LaFhtjoh1F_PcWnC1B
"""

!pip install pandas
!pip install chardet

import numpy as np # it is created for numpy arrays
import pandas as pd # it is for dataframe , for structuring dataframes
from sklearn.model_selection import train_test_split #for test running the model
from sklearn.feature_extraction.text import TfidfVectorizer # it will convert text to numerical value
from sklearn.linear_model import LogisticRegression #to classify mail spam or ham
from sklearn.metrics import accuracy_score #to check the frequency of output data
import chardet
from sklearn.naive_bayes import MultinomialNB

# Loading data from csv to pandas dataframe
with open('/content/spam.csv', 'rb') as f:
    encoding = chardet.detect(f.read())['encoding']
r_data = pd.read_csv('/content/spam.csv', encoding=encoding) #using pandas here to convert csv file

r_data['v1'] = r_data['v1'].map({'ham':0, 'spam': 1})
r_data.head()

a = r_data['v2']
b = r_data['v1']
#Splitting the data into training data and test data

a_train, a_test, b_train, b_test = train_test_split(a, b, test_size = 0.2, random_state = 3)

#Feature Extraction

#transform the text data to featute vectors that can be used as input to the logistic regression

feature_extraction = TfidfVectorizer(min_df = 1, stop_words = 'english', lowercase = True) #it gives score to all the words for their no. of repeatations
#if score of words is greaterthan 1, it will be ignored
#stop words ignores unimportant words

a_train_features = feature_extraction.fit_transform(a_train) #it will fit all data into vectorizers
a_test_features = feature_extraction.transform(a_test) #we just want to transform data

b_train = b_train.astype('int')
b_test = b_test.astype('int')

# Logistic Regression
model = LogisticRegression()
model.fit(a_train_features, b_train)

#just predicting
prediction_on_training_data = model.predict(a_train_features)
accuracy_on_training_data = accuracy_score(b_train, prediction_on_training_data)



# prediction on test data
prediction_on_test_data = model.predict(a_test_features)
accuracy_on_test_data = accuracy_score(b_test, prediction_on_test_data)



# Building a Predictive System
input_mail = ['Hurrayyy you won $550000000 !!!!!!!!!']
# convert text to feature vectors
input_data_features = feature_extraction.transform(input_mail)

# making prediction
prediction = model.predict(input_data_features)

if prediction[0] == 1:
    print('Ham mail')
else:
    print('Spam mail')

"""# New Section

# New Section

# New Section
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

dfv = pd.read_csv('spam.csv' , encoding = "latin-1")

dfv

dfv.drop(columns = ['Unnamed: 2','Unnamed: 3','Unnamed: 4'], inplace = True)

dfv

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

dfv['v1'] = encoder.fit_transform(dfv['v1'])

dfv.isna().sum()

dfv.duplicated().sum()

dfv.drop_duplicates(keep = 'first', inplace = True)

dfv.duplicated().sum()

dfv.head()

dfv['v1'].value_counts()

import matplotlib.pyplot as plt

import nltk

import string
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def transform_text(text):
  text = text.lower()

  text = nltk.word_tokenize(text)
  y=[]
  for i in text:
    if i.isalnum():
      y.append(i)


  text = y[:]
  y.clear()

  for i in text:
    if i not in stopwords.words('english') and i not in string.punctuation:
      y.append(i)


  text = y[:]
  y.clear()


  for i in text:
    y.append(ps.stem(i))

  return " ".join(y)

from nltk.corpus import stopwords

nltk.download("stopwords")

stopwords.words("english")

ps.stem("danceing")

dfv["transform_text"]=dfv['v2'].apply(transform_text)

from wordcloud import WordCloud
wc = WordCloud(width = 700, height = 700, min_font_size = 10, background_color = 'yellow')

spam_wc = wc.generate(dfv[dfv["v1"]== 1]["transform_text"].str.cat(sep=" "))

spam_corpus=[]
for msg in dfv[dfv["v1"]== 1]["transform_text"].tolist():
  for word in msg.split():
    spam_corpus.append(word)

from collections import Counter
pd.DataFrame(Counter(spam_corpus).most_common(50))

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
cv = CountVectorizer()
tf = TfidfVectorizer()

X = tf.fit_transform(dfv['transform_text']).toarray()

Y = dfv["v1"].values

Y

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)

from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB
from sklearn.metrics import accuracy_score

gnv = GaussianNB()
mnv = MultinomialNB()
bnv = BernoulliNB()

from sklearn.naive_bayes import MultinomialNB

mnv = MultinomialNB()

# Fit the classifier to the training data
mnv.fit(X_train, Y_train)

# Make predictions on the test data
predictions = mnv.predict(X_test)

from sklearn.linear_model import LogisticRegression

import pickle
pickle.dump(tf, open("vectorizer.pkl","wb"))
pickle.dump(mnv, open("spam.pkl","wb"))

dfv["transform_text"][4532]

# Commented out IPython magic to ensure Python compatibility.
# %%writefile appy.py
# import streamlit as st
# import pickle
# import sklearn
# from nltk.corpus import stopwords
# import nltk
# import string
# from nltk.stem.porter import PorterStemmer
# ps = PorterStemmer()
# nltk.download('punkt')
# nltk.download('stopwords')
# 
# 
# 
# 
# def transform_text(text):
#     text = text.lower()
# 
#     text= nltk.word_tokenize(text)
#     y = []
#     for i in text:
#         if i.isalnum():
#             y.append(i)
# 
# 
#     text = y[:]
#     y.clear()
# 
#     for i in text:
#         if i not in stopwords.words('english') and  i not in string.punctuation:
#             y.append(i)
# 
#     text = y[:]
#     y.clear()
# 
#     for i in text:
#         y.append(ps.stem(i))
# 
# 
#     return " ".join(y)
# 
# 
# 
# tf = pickle.load(open('vectorizer.pkl', 'rb'))
# model = pickle.load(open('spam.pkl', 'rb'))
# 
# 
# st.title('Email Spam Classifier')
# 
# input_sms = st.text_input('Enter the Message ')
# 
# option = st.selectbox("You Got Message From :-", ["Via Email ", "Via SMS", "other"])
# 
# 
# 
# if st.button('Click to Predict'):
#     transform_sms = transform_text(input_sms)
#     vector_input = tf.transform([transform_sms])
#     result = model.predict(vector_input)[0]
# 
#     if result == 1:
#         st.error("Spam")
#     else:
#         st.success('Not Spam')
# 
#

!streamlit run appy.py & npx localtunnel --port 8501



